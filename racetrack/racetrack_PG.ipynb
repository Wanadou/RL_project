{"cells":[{"cell_type":"markdown","metadata":{"id":"bDdMCr88Ssp4"},"source":["This notebook implements a policy gradient method to tackle the racetrack RL environment. We have a continuous action space so we cannot softmax. We therefore use a neural network to predict mean and standard deviation of a normal distribution. We then sample actions with respect to this distribution to compute loss and train the neural network."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1714637935505,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"GHnelLdqSsp8","outputId":"c4cfcd18-9d90-49da-c196-d89b62acccb2"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment exit-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment highway-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment highway-fast-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment intersection-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment intersection-v1 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment intersection-multi-agent-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment intersection-multi-agent-v1 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment lane-keeping-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment merge-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment parking-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment parking-ActionRepeat-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment parking-parked-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment racetrack-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment roundabout-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment two-way-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment u-turn-v0 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"]}],"source":["import highway_env\n","from reinforce import REINFORCE\n","highway_env.register_highway_envs()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1714637935505,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"taOORbZ5Ssp-"},"outputs":[],"source":["# Imports\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from copy import deepcopy\n","import time\n","import os\n","os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n","from IPython.display import clear_output\n","import gymnasium as gym\n","from gymnasium.wrappers import RecordVideo\n","\n","import matplotlib.pyplot as plt\n","import pprint"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1168,"status":"ok","timestamp":1714637936666,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"AykO3HFRW5Ct","outputId":"5e969a17-3281-4ccf-b338-31b4616b9fa0"},"outputs":[{"data":{"text/plain":["(array([[[0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 1., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.]],\n"," \n","        [[1., 1., 1., 1., 1., 0., 0.],\n","         [1., 1., 1., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1.],\n","         [1., 1., 1., 1., 1., 1., 1.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.]]], dtype=float32),\n"," {'speed': 10,\n","  'crashed': False,\n","  'action': array([0.21704124], dtype=float32),\n","  'rewards': {'lane_centering_reward': 1.0,\n","   'action_reward': 0.21704124,\n","   'collision_reward': False,\n","   'on_road_reward': True}})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["env = gym.make(\"racetrack-v0\", render_mode=\"rgb_array\")\n","\n","config = {\n","    \"observation\": {\n","        \"type\": \"OccupancyGrid\",\n","        \"features\": [\"presence\", \"on_road\"],\n","        \"grid_size\": [[-18, 18], [-18, 18]],\n","        \"grid_step\": [5, 5],\n","        \"as_image\": False,\n","        \"align_to_vehicle_axes\": True\n","    },\n","    \"action\": {\n","        \"type\": \"ContinuousAction\",\n","        \"longitudinal\": False,\n","        \"lateral\": True,\n","        \"steering_range\": [-np.pi / 4, np.pi / 4],  # [rad]\n","        #\"acceleration_range\": [-2, 2],  # [m/s²]\n","        \"speed_range\": [0, 15],  # [m/s]\n","    },\n","    \"simulation_frequency\": 15,\n","    \"policy_frequency\": 5,\n","    \"duration\": 300,\n","    \"collision_reward\": -1,\n","    \"lane_centering_cost\": 4,\n","    \"action_reward\": -0.3,\n","    \"controlled_vehicles\": 1,\n","    \"other_vehicles\": 1,\n","    \"screen_width\": 600,\n","    \"screen_height\": 600,\n","    \"centering_position\": [0.5, 0.5],\n","    \"scaling\": 7,\n","    \"show_trajectories\": False,\n","    \"render_agent\": True,\n","    \"offscreen_rendering\": False\n","}\n","\n","\n","env.unwrapped.configure(config)\n","env.reset()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1714637936668,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"_iiGGe31Ssp_","outputId":"995f95ab-f6fb-4fdf-ca49-40d9f0627c2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["EnvSpec(id='racetrack-v0', entry_point='highway_env.envs:RacetrackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'render_mode': 'rgb_array'}, namespace=None, name='racetrack', version=0, additional_wrappers=(), vector_entry_point=None)\n","{'action': {'lateral': True,\n","            'longitudinal': False,\n","            'speed_range': [0, 15],\n","            'steering_range': [-0.7853981633974483, 0.7853981633974483],\n","            'type': 'ContinuousAction'},\n"," 'action_reward': -0.3,\n"," 'centering_position': [0.5, 0.5],\n"," 'collision_reward': -1,\n"," 'controlled_vehicles': 1,\n"," 'duration': 300,\n"," 'lane_centering_cost': 4,\n"," 'lane_centering_reward': 1,\n"," 'manual_control': False,\n"," 'observation': {'align_to_vehicle_axes': True,\n","                 'as_image': False,\n","                 'features': ['presence', 'on_road'],\n","                 'grid_size': [[-18, 18], [-18, 18]],\n","                 'grid_step': [5, 5],\n","                 'type': 'OccupancyGrid'},\n"," 'offscreen_rendering': False,\n"," 'other_vehicles': 1,\n"," 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n"," 'policy_frequency': 5,\n"," 'real_time_rendering': False,\n"," 'render_agent': True,\n"," 'scaling': 7,\n"," 'screen_height': 600,\n"," 'screen_width': 600,\n"," 'show_trajectories': False,\n"," 'simulation_frequency': 15}\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.config to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.config` for environment variables or `env.get_wrapper_attr('config')` that will search the reminding wrappers.\u001b[0m\n","  logger.warn(\n"]}],"source":["print(env.spec)\n","pprint.pprint(env.config)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714637936668,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"cPYpMweLSsqA"},"outputs":[],"source":["#The baseline agent to compare performances\n","\n","class RandomAgent:\n","    def __init__(self, observation_space, action_space):\n","        self.action_space = action_space\n","        return\n","\n","    def get_action(self, state, **kwargs):\n","        return self.action_space.sample()\n","\n","    def update(self, *data):\n","        pass"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1714638028611,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"6y-QJvASSsqA"},"outputs":[],"source":["def eval_agent(agent, env, n_sim=10):\n","    \"\"\"\n","    Monte Carlo evaluation of the agent.\n","\n","    Repeat n_sim times:\n","        * Run the agent policy until the environment reaches a terminal state (= one episode)\n","        * Compute the sum of rewards in this episode\n","        * Store the sum of rewards in the episode_rewards array.\n","    \"\"\"\n","    env_copy = deepcopy(env)\n","    episode_rewards = np.zeros(n_sim)\n","    for i in range(n_sim):\n","        state, _ = env_copy.reset()\n","        reward_sum = 0\n","        done = False\n","        while not done:\n","            action = agent.get_action(state, epsilon=0)\n","            #print(action)\n","            state, reward, terminated, truncated, _ = env_copy.step(action)\n","            reward_sum += reward\n","            done = terminated or truncated\n","        episode_rewards[i] = reward_sum\n","    return episode_rewards"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714637936670,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"UfCi5uoUSsqB"},"outputs":[],"source":["\n","#agent = RandomAgent(env.observation_space, env.action_space)\n","\n","def run_one_episode(env, agent, display=True):\n","    display_env = deepcopy(env)\n","    done = False\n","    state, _ = display_env.reset()\n","\n","    rewards = 0\n","\n","    while not done:\n","\n","        action = agent.get_action(state, epsilon=0)\n","        state, reward, done, _, _ = display_env.step(action)\n","        rewards += reward\n","        if display:\n","            clear_output(wait=True)\n","            plt.imshow(display_env.render())\n","            plt.show()\n","    if display:\n","        display_env.close()\n","    print(f'Episode length {rewards}')\n","\n","# run_one_episode(env, agent, display=False)\n","# print(f'Average over 5 runs : {np.mean(eval_agent(agent, env))}')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1714639475361,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"bcW56vTWSsqB"},"outputs":[],"source":["def train(env, agent, N_episodes, eval_every=100, reward_threshold=400, n_eval=10):\n","    total_time = 0\n","    for ep in range(N_episodes):\n","        done = False\n","        state, _ = env.reset()\n","        while not done:\n","            action = agent.get_action(state, epsilon = 0)\n","            #print(action)\n","            next_state, reward, terminated, truncated, _ = env.step(action)\n","            agent.update(state, action, reward, terminated, next_state)\n","\n","            state = next_state\n","\n","            done = terminated or truncated\n","            total_time += 1\n","\n","        if ((ep+1)% eval_every == 0):\n","            mean_reward = np.mean(eval_agent(agent, env, n_sim=n_eval))\n","            print(\"episode =\", ep+1, \", reward = \", mean_reward)\n","            if mean_reward >= reward_threshold:\n","                break\n","\n","    return"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535484,"status":"ok","timestamp":1714640104136,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"ZwVRBD6xSsqC","outputId":"7a3d119f-db9e-452b-a95e-b14073ad2269"},"outputs":[{"name":"stdout","output_type":"stream","text":["mean reward after training =  11.03581000881692\n","[10.15108582 10.0008364  26.21282753 22.95331702 29.98349032 13.66242371\n"," 31.7738181   7.0698197  15.46031989  1.04911098]\n"]}],"source":["\n","\n","# action_space = env.action_space\n","# observation_space = env.observation_space\n","\n","# gamma = .95\n","# episode_batch_size = 30\n","# learning_rate = 1e-2\n","\n","# agent = REINFORCE(\n","#         action_space,\n","#         observation_space,\n","#         gamma,\n","#         episode_batch_size,\n","#         learning_rate,\n","#         )\n","# N_episodes = 3000\n","\n","gamma = 0.8\n","batch_size = 32\n","buffer_capacity = 15_000\n","#update_target_every = 32\n","\n","epsilon_start = 0.4 #0.8\n","decrease_epsilon_factor = 50 #100\n","epsilon_min = 0.02\n","\n","# hidden_size = 256\n","input_channels = 2\n","\n","learning_rate = 5e-4\n","\n","agent = REINFORCE(env,\n","            gamma,\n","            batch_size,\n","            buffer_capacity,\n","            epsilon_start,\n","            decrease_epsilon_factor,\n","            epsilon_min,\n","            learning_rate,\n","            input_channels\n","        )\n","N_episodes = 100\n","\n","\n","#print(\"mean reward before training = \", np.mean(eval_agent(agent, env, 1)))\n","# Run the training loop\n","train(env, agent, N_episodes, eval_every=50,)\n","\n","# Evaluate the final policy\n","print(\"mean reward after training = \", np.mean(eval_agent(agent, env, 20)))\n","print(eval_agent(agent, env, 20))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1714638023272,"user":{"displayName":"Arnó Heckel","userId":"14267454093224354874"},"user_tz":-120},"id":"OBD64mQWSsqC"},"outputs":[{"ename":"DependencyNotInstalled","evalue":"moviepy is not installed, run `pip install moviepy`","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\wrappers\\monitoring\\video_recorder.py:55\u001b[0m, in \u001b[0;36mVideoRecorder.__init__\u001b[1;34m(self, env, path, metadata, enabled, base_path, disable_logger)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# check that moviepy is now installed\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      7\u001b[0m     done \u001b[38;5;241m=\u001b[39m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\wrappers\\record_video.py:129\u001b[0m, in \u001b[0;36mRecordVideo.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_video_recorder()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_video_enabled():\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_video_recorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observations\n","File \u001b[1;32mc:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\wrappers\\record_video.py:141\u001b[0m, in \u001b[0;36mRecordVideo.start_video_recorder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     video_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-episode-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_folder, video_name)\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_recorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoRecorder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder\u001b[38;5;241m.\u001b[39mcapture_frame()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[1;32mc:\\Users\\arnoh\\anaconda3\\envs\\pytorch_old_python\\Lib\\site-packages\\gymnasium\\wrappers\\monitoring\\video_recorder.py:57\u001b[0m, in \u001b[0;36mVideoRecorder.__init__\u001b[1;34m(self, env, path, metadata, enabled, base_path, disable_logger)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoviepy is not installed, run `pip install moviepy`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mansi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mansi_list\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is incompatible with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m RecordVideo. Initialize your environment with a render_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m that returns an image, such as rgb_array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m     )\n","\u001b[1;31mDependencyNotInstalled\u001b[0m: moviepy is not installed, run `pip install moviepy`"]}],"source":["# env = RecordVideo(\n","#     env, video_folder=\"racetrack_PG/videos\", episode_trigger=lambda e: True\n","# )\n","# env.unwrapped.set_record_video_wrapper(env)\n","\n","# for video in range(10):\n","#     done = truncated = False\n","#     obs, info = env.reset()\n","#     while not (done or truncated):\n","#         # Predict\n","#         action, _states = model.predict(obs, deterministic=True)\n","#         # Get reward\n","#         obs, reward, done, truncated, info = env.step(action)\n","#         # Render\n","#         env.render()\n","# env.close()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"pytorch_old_python","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
